{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate, SpatialDropout1D, TimeDistributed, Bidirectional, LSTM, Flatten\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from tensorflow.keras import optimizers, losses, activations, models\n",
    "\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "import seaborn as sn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.36787944117144233, 2.718281828459045, 72.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-1), np.exp(1), 200 * 0.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model():\n",
    "    inp = Input(shape=(500, 64))\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
    "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = SpatialDropout1D(rate=0.01)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = SpatialDropout1D(rate=0.01)(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
    "    img_1 = SpatialDropout1D(rate=0.01)(img_1)\n",
    "    img_1 = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "    out = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
    "#     out = GlobalMaxPool1D()(img_1)\n",
    "\n",
    "\n",
    "    base_model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(0.001)\n",
    "\n",
    "    base_model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
    "    #model.summary()\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_lstm():\n",
    "    nclass = 3\n",
    "\n",
    "    seq_input = Input(shape=(500, 64))\n",
    "    base_model = get_base_model()\n",
    "    encoded_sequence = base_model(seq_input)\n",
    "    encoded_sequence = Bidirectional(LSTM(100, return_sequences=True))(encoded_sequence)\n",
    "    encoded_sequence = Dropout(rate=0.5)(encoded_sequence)\n",
    "    encoded_sequence = Bidirectional(LSTM(100, return_sequences=True))(encoded_sequence)\n",
    "    encoded_sequence = Flatten()(encoded_sequence)\n",
    "    out = Dense(nclass, activation=\"softmax\")(encoded_sequence)\n",
    "#     out = Convolution1D(nclass, kernel_size=1, activation=\"softmax\", padding=\"same\")(encoded_sequence)\n",
    "\n",
    "    model = models.Model(seq_input, out)\n",
    "\n",
    "    model.compile(optimizers.Adam(0.001), losses.categorical_crossentropy, metrics=['acc'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_model_nn():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1000, input_shape=(500, 64), activation=\"relu\"))\n",
    "    model.add(Dense(800, activation=\"relu\"))\n",
    "    model.add(Dense(500, activation=\"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(3, activation=\"relu\"))\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, path, X, Y, target_shape=None, batch_size=32, num_classes=None, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.path = path\n",
    "        self.target_shape = target_shape\n",
    "        self.Y = Y\n",
    "        self.indices = X\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = self.indices[index]\n",
    "        \n",
    "        X, y = self.__get_data(batch)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.index = np.arange(len(self.indices))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.index)\n",
    "\n",
    "    def __get_data(self, batch):\n",
    "        t_d, ch_d = self.target_shape\n",
    "        \n",
    "        X = np.empty((len(batch), t_d, ch_d))\n",
    "        y = np.empty((len(batch), self.num_classes))\n",
    "        \n",
    "        for i, id in enumerate(batch):\n",
    "            path = os.path.join(self.path, '{}.npy'.format(id))\n",
    "            X[i,] = np.load(path)\n",
    "            y[i] = self.Y[id-1]\n",
    "            \n",
    "        X = np.swapaxes(X, 1,2)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RT-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/Y_train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-682c252cb82f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/X_test.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/Y_train.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# Y_val = np.load(\"data/Y_val.npy\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/Y_test.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/Y_train.npy'"
     ]
    }
   ],
   "source": [
    "X_train = np.load(\"data/X_train.npy\")\n",
    "# X_val = np.load(\"data/X_val.npy\")\n",
    "X_test = np.load(\"data/X_test.npy\")\n",
    "\n",
    "Y_train = np.load(\"data/Y_train.npy\")\n",
    "# Y_val = np.load(\"data/Y_val.npy\")\n",
    "Y_test = np.load(\"data/Y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.swapaxes(X_train, 1,2)\n",
    "X_test = np.swapaxes(X_test, 1,2)\n",
    "X_val = np.swapaxes(X_val, 1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37501, 500, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 498, 16)           3088      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 498, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 498, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 496, 16)           784       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 496, 16)           64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 496, 16)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 493, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 491, 32)           1568      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 491, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 491, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 489, 32)           3104      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 489, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 489, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 122, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 120, 32)           3104      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 120, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 120, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 118, 32)           3104      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 118, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 118, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 29, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 928)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                59456     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 75,299\n",
      "Trainable params: 74,851\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = temporal_model()\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "tb = TensorBoard(log_dir=\"Tensorboard\")\n",
    "ch = ModelCheckpoint(\"models/t-vgg_mod_10.h5\", monitor='val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37501 samples, validate on 17500 samples\n",
      "Epoch 1/60\n",
      "   32/37501 [..............................] - ETA: 3:16:56 - loss: 3.5357 - accuracy: 0.2812WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.236954). Check your callbacks.\n",
      "   64/37501 [..............................] - ETA: 1:39:56 - loss: 3.5637 - accuracy: 0.3125WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.102448). Check your callbacks.\n",
      "37501/37501 [==============================] - 24s 634us/sample - loss: 1.9948 - accuracy: 0.6137 - val_loss: 1.4217 - val_accuracy: 0.7737\n",
      "Epoch 2/60\n",
      "37501/37501 [==============================] - 13s 347us/sample - loss: 1.2053 - accuracy: 0.7913 - val_loss: 0.9923 - val_accuracy: 0.8414\n",
      "Epoch 3/60\n",
      "37501/37501 [==============================] - 13s 346us/sample - loss: 0.8883 - accuracy: 0.8480 - val_loss: 0.7613 - val_accuracy: 0.8796\n",
      "Epoch 4/60\n",
      "37501/37501 [==============================] - 13s 346us/sample - loss: 0.7003 - accuracy: 0.8795 - val_loss: 0.6203 - val_accuracy: 0.8973\n",
      "Epoch 5/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.5767 - accuracy: 0.9010 - val_loss: 0.5186 - val_accuracy: 0.9122\n",
      "Epoch 6/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.4921 - accuracy: 0.9139 - val_loss: 0.4522 - val_accuracy: 0.9246\n",
      "Epoch 7/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.4263 - accuracy: 0.9265 - val_loss: 0.4108 - val_accuracy: 0.9265\n",
      "Epoch 8/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.3733 - accuracy: 0.9359 - val_loss: 0.3605 - val_accuracy: 0.9358\n",
      "Epoch 9/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.3311 - accuracy: 0.9435 - val_loss: 0.3284 - val_accuracy: 0.9413\n",
      "Epoch 10/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.2995 - accuracy: 0.9481 - val_loss: 0.2945 - val_accuracy: 0.9465\n",
      "Epoch 11/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.2744 - accuracy: 0.9525 - val_loss: 0.2863 - val_accuracy: 0.9467\n",
      "Epoch 12/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.2455 - accuracy: 0.9564 - val_loss: 0.2564 - val_accuracy: 0.9483\n",
      "Epoch 13/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.2260 - accuracy: 0.9621 - val_loss: 0.2286 - val_accuracy: 0.9567\n",
      "Epoch 14/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.2098 - accuracy: 0.9633 - val_loss: 0.2134 - val_accuracy: 0.9598\n",
      "Epoch 15/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.1969 - accuracy: 0.9662 - val_loss: 0.2243 - val_accuracy: 0.9522\n",
      "Epoch 16/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.1811 - accuracy: 0.9697 - val_loss: 0.1870 - val_accuracy: 0.9624\n",
      "Epoch 17/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.1708 - accuracy: 0.9697 - val_loss: 0.1749 - val_accuracy: 0.9666\n",
      "Epoch 18/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.1574 - accuracy: 0.9742 - val_loss: 0.1776 - val_accuracy: 0.9633\n",
      "Epoch 19/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.1542 - accuracy: 0.9723 - val_loss: 0.1858 - val_accuracy: 0.9585\n",
      "Epoch 20/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.1445 - accuracy: 0.9747 - val_loss: 0.1712 - val_accuracy: 0.9622\n",
      "Epoch 21/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.1375 - accuracy: 0.9762 - val_loss: 0.1614 - val_accuracy: 0.9639\n",
      "Epoch 22/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.1299 - accuracy: 0.9775 - val_loss: 0.1560 - val_accuracy: 0.9662\n",
      "Epoch 23/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.1230 - accuracy: 0.9792 - val_loss: 0.1528 - val_accuracy: 0.9650\n",
      "Epoch 24/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.1193 - accuracy: 0.9790 - val_loss: 0.1625 - val_accuracy: 0.9631\n",
      "Epoch 25/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.1147 - accuracy: 0.9791 - val_loss: 0.1590 - val_accuracy: 0.9630\n",
      "Epoch 26/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.1144 - accuracy: 0.9787 - val_loss: 0.1383 - val_accuracy: 0.9683\n",
      "Epoch 27/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.1032 - accuracy: 0.9825 - val_loss: 0.1861 - val_accuracy: 0.9505\n",
      "Epoch 28/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.1012 - accuracy: 0.9827 - val_loss: 0.1349 - val_accuracy: 0.9689\n",
      "Epoch 29/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.1033 - accuracy: 0.9810 - val_loss: 0.1267 - val_accuracy: 0.9722\n",
      "Epoch 30/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.0967 - accuracy: 0.9837 - val_loss: 0.1194 - val_accuracy: 0.9727\n",
      "Epoch 31/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0924 - accuracy: 0.9842 - val_loss: 0.1401 - val_accuracy: 0.9662\n",
      "Epoch 32/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0928 - accuracy: 0.9838 - val_loss: 0.1162 - val_accuracy: 0.9740\n",
      "Epoch 33/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0904 - accuracy: 0.9838 - val_loss: 0.1217 - val_accuracy: 0.9723\n",
      "Epoch 34/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0900 - accuracy: 0.9849 - val_loss: 0.1345 - val_accuracy: 0.9668\n",
      "Epoch 35/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.0896 - accuracy: 0.9842 - val_loss: 0.1485 - val_accuracy: 0.9625\n",
      "Epoch 36/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0865 - accuracy: 0.9849 - val_loss: 0.1101 - val_accuracy: 0.9755\n",
      "Epoch 37/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0855 - accuracy: 0.9851 - val_loss: 0.1285 - val_accuracy: 0.9684\n",
      "Epoch 38/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0816 - accuracy: 0.9864 - val_loss: 0.1099 - val_accuracy: 0.9735\n",
      "Epoch 39/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0837 - accuracy: 0.9851 - val_loss: 0.1066 - val_accuracy: 0.9757\n",
      "Epoch 40/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0813 - accuracy: 0.9858 - val_loss: 0.1092 - val_accuracy: 0.9744\n",
      "Epoch 41/60\n",
      "37501/37501 [==============================] - 13s 346us/sample - loss: 0.0807 - accuracy: 0.9864 - val_loss: 0.1155 - val_accuracy: 0.9727\n",
      "Epoch 42/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0776 - accuracy: 0.9870 - val_loss: 0.1266 - val_accuracy: 0.9694\n",
      "Epoch 43/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0800 - accuracy: 0.9866 - val_loss: 0.1092 - val_accuracy: 0.9759\n",
      "Epoch 44/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.0778 - accuracy: 0.9870 - val_loss: 0.1183 - val_accuracy: 0.9729\n",
      "Epoch 45/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0774 - accuracy: 0.9870 - val_loss: 0.1068 - val_accuracy: 0.9744\n",
      "Epoch 46/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.0750 - accuracy: 0.9884 - val_loss: 0.1007 - val_accuracy: 0.9771\n",
      "Epoch 47/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0776 - accuracy: 0.9870 - val_loss: 0.1075 - val_accuracy: 0.9759\n",
      "Epoch 48/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0769 - accuracy: 0.9866 - val_loss: 0.1346 - val_accuracy: 0.9665\n",
      "Epoch 49/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0751 - accuracy: 0.9875 - val_loss: 0.1053 - val_accuracy: 0.9765\n",
      "Epoch 50/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0750 - accuracy: 0.9871 - val_loss: 0.1461 - val_accuracy: 0.9621\n",
      "Epoch 51/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.0728 - accuracy: 0.9884 - val_loss: 0.1712 - val_accuracy: 0.9527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.0711 - accuracy: 0.9890 - val_loss: 0.1056 - val_accuracy: 0.9762\n",
      "Epoch 53/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.0700 - accuracy: 0.9890 - val_loss: 0.1194 - val_accuracy: 0.9728\n",
      "Epoch 54/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0740 - accuracy: 0.9872 - val_loss: 0.1037 - val_accuracy: 0.9778\n",
      "Epoch 55/60\n",
      "37501/37501 [==============================] - 13s 346us/sample - loss: 0.0680 - accuracy: 0.9898 - val_loss: 0.0985 - val_accuracy: 0.9780\n",
      "Epoch 56/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.0718 - accuracy: 0.9885 - val_loss: 0.0965 - val_accuracy: 0.9799\n",
      "Epoch 57/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0676 - accuracy: 0.9900 - val_loss: 0.0997 - val_accuracy: 0.9778\n",
      "Epoch 58/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0699 - accuracy: 0.9887 - val_loss: 0.1005 - val_accuracy: 0.9767\n",
      "Epoch 59/60\n",
      "37501/37501 [==============================] - 13s 344us/sample - loss: 0.0690 - accuracy: 0.9887 - val_loss: 0.1093 - val_accuracy: 0.9759\n",
      "Epoch 60/60\n",
      "37501/37501 [==============================] - 13s 345us/sample - loss: 0.0699 - accuracy: 0.9893 - val_loss: 0.1138 - val_accuracy: 0.9741\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(x=X_train, y=Y_train, epochs=60, validation_data=[X_val, Y_val], callbacks=[tb,ch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd4c83a4208>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = h.history\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(15,6))\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)\n",
    "\n",
    "axs[0].set_title(\"Loss Curve\", fontdict={'size':15, 'weight':'bold'})\n",
    "axs[0].plot(history['loss'], label='Training')\n",
    "axs[0].plot(history['val_loss'], label='Validation')\n",
    "axs[0].set_xlabel(\"epoch\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_title(\"Accuracy Curve\", fontdict={'size':15, 'weight':'bold'})\n",
    "axs[1].plot(history['accuracy'], label='Training')\n",
    "axs[1].plot(history['val_accuracy'], label='Validation')\n",
    "axs[1].set_xlabel(\"epoch\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[1].legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(\"models/t-vgg_mod_10.h5\")\n",
    "Y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-240ace4c90d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \"\"\"\n\u001b[0;32m-> 1153\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "Y_pred = np.argmax(Y_pred, axis=1)\n",
    "Y_test= np.argmax(Y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1534\n",
      "           1       0.97      0.98      0.97      2956\n",
      "           2       0.98      0.98      0.98      3034\n",
      "\n",
      "    accuracy                           0.98      7524\n",
      "   macro avg       0.98      0.97      0.98      7524\n",
      "weighted avg       0.98      0.98      0.98      7524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot()\n",
    "sn.heatmap(confusion_matrix(Y_test, Y_pred, normalize='pred'), \n",
    "           annot=True, fmt='.2g', cmap=cm.Blues, ax = ax, cbar=True)\n",
    "\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['slow', 'med', 'fast']); ax.yaxis.set_ticklabels(['slow', 'med', 'fast']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RT-ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"data/X_train_st.npy\")\n",
    "X_test = np.load(\"data/X_test_st.npy\")\n",
    "\n",
    "Y_train = pd.read_csv(\"data/Y_train_st.csv\")\n",
    "Y_test = pd.read_csv(\"data/Y_test_st.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((-1, 64, 500))\n",
    "X_test = X_test.reshape((-1, 64, 500))\n",
    "\n",
    "X_train = np.swapaxes(X_train, 1,2)\n",
    "X_test = np.swapaxes(X_test, 1,2)\n",
    "\n",
    "y_train = Y_train['labels'].values\n",
    "y_test = Y_test['labels'].values\n",
    "\n",
    "\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 500, 64)]         0         \n",
      "_________________________________________________________________\n",
      "model (Model)                (None, 54, 64)            35872     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 54, 200)           132000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 54, 200)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 54, 200)           240800    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 32403     \n",
      "=================================================================\n",
      "Total params: 441,075\n",
      "Trainable params: 441,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model_lstm()\n",
    "\n",
    "tb = TensorBoard(log_dir=\"Tensorboard\")\n",
    "ch = ModelCheckpoint(\"models/t-vgg_mod_st_1.h5\", monitor='val_acc', save_best_only=True, mode='max')\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=2, min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_it = DataGenerator(X_train, Y_train, num_classes=3, batch_size=256)\n",
    "\n",
    "test_it = DataGenerator(X_test, Y_test, num_classes=3, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "133/133 [==============================] - 25s 188ms/step - loss: 0.8341 - acc: 0.6656 - val_loss: 0.7962 - val_acc: 0.6757\n",
      "Epoch 2/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.7917 - acc: 0.6692 - val_loss: 0.7669 - val_acc: 0.6808\n",
      "Epoch 3/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.7669 - acc: 0.6802 - val_loss: 0.7668 - val_acc: 0.6813\n",
      "Epoch 4/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.7551 - acc: 0.6853 - val_loss: 0.7445 - val_acc: 0.6914\n",
      "Epoch 5/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.7446 - acc: 0.6906 - val_loss: 0.7612 - val_acc: 0.6824\n",
      "Epoch 6/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.7410 - acc: 0.6916 - val_loss: 0.7331 - val_acc: 0.6952\n",
      "Epoch 7/500\n",
      "133/133 [==============================] - 24s 178ms/step - loss: 0.7284 - acc: 0.6973 - val_loss: 0.7389 - val_acc: 0.6955\n",
      "Epoch 8/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.7250 - acc: 0.6994 - val_loss: 0.7419 - val_acc: 0.6955\n",
      "Epoch 9/500\n",
      "133/133 [==============================] - 24s 178ms/step - loss: 0.7202 - acc: 0.6993 - val_loss: 0.7359 - val_acc: 0.7013\n",
      "Epoch 10/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.7153 - acc: 0.7038 - val_loss: 0.7271 - val_acc: 0.6995\n",
      "Epoch 11/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.7113 - acc: 0.7058 - val_loss: 0.7231 - val_acc: 0.7013\n",
      "Epoch 12/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.7076 - acc: 0.7070 - val_loss: 0.7217 - val_acc: 0.7039\n",
      "Epoch 13/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.6970 - acc: 0.7106 - val_loss: 0.7173 - val_acc: 0.7041\n",
      "Epoch 14/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.6904 - acc: 0.7138 - val_loss: 0.7206 - val_acc: 0.7037\n",
      "Epoch 15/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.6861 - acc: 0.7148 - val_loss: 0.7084 - val_acc: 0.7061\n",
      "Epoch 16/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.6808 - acc: 0.7174 - val_loss: 0.7140 - val_acc: 0.7045\n",
      "Epoch 17/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.6754 - acc: 0.7209 - val_loss: 0.7166 - val_acc: 0.7072\n",
      "Epoch 18/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.6704 - acc: 0.7216 - val_loss: 0.7067 - val_acc: 0.7116\n",
      "Epoch 19/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.6650 - acc: 0.7261 - val_loss: 0.7059 - val_acc: 0.7119\n",
      "Epoch 20/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.6607 - acc: 0.7253 - val_loss: 0.7075 - val_acc: 0.7100\n",
      "Epoch 21/500\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.6559 - acc: 0.7303 - val_loss: 0.7097 - val_acc: 0.7088\n",
      "Epoch 22/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.6517 - acc: 0.7324 - val_loss: 0.7148 - val_acc: 0.7037\n",
      "Epoch 23/500\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.6449 - acc: 0.7322 - val_loss: 0.7223 - val_acc: 0.7058\n",
      "Epoch 24/500\n",
      "133/133 [==============================] - 24s 184ms/step - loss: 0.6383 - acc: 0.7338 - val_loss: 0.7087 - val_acc: 0.7121\n",
      "Epoch 25/500\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.6368 - acc: 0.7363 - val_loss: 0.7144 - val_acc: 0.7049\n",
      "Epoch 26/500\n",
      "133/133 [==============================] - 25s 184ms/step - loss: 0.6303 - acc: 0.7376 - val_loss: 0.7126 - val_acc: 0.7044\n",
      "Epoch 27/500\n",
      "133/133 [==============================] - 24s 184ms/step - loss: 0.6260 - acc: 0.7402 - val_loss: 0.7108 - val_acc: 0.7072\n",
      "Epoch 28/500\n",
      "133/133 [==============================] - 24s 184ms/step - loss: 0.6188 - acc: 0.7440 - val_loss: 0.7439 - val_acc: 0.6975\n",
      "Epoch 29/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.6123 - acc: 0.7476\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "133/133 [==============================] - 24s 184ms/step - loss: 0.6121 - acc: 0.7477 - val_loss: 0.7247 - val_acc: 0.7079\n",
      "Epoch 30/500\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.5719 - acc: 0.7637 - val_loss: 0.7454 - val_acc: 0.7077\n",
      "Epoch 31/500\n",
      "133/133 [==============================] - 24s 184ms/step - loss: 0.5548 - acc: 0.7731 - val_loss: 0.7589 - val_acc: 0.7040\n",
      "Epoch 32/500\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.5497 - acc: 0.7740 - val_loss: 0.7659 - val_acc: 0.7009\n",
      "Epoch 33/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5444 - acc: 0.7768 - val_loss: 0.7741 - val_acc: 0.6983\n",
      "Epoch 34/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5385 - acc: 0.7773\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5383 - acc: 0.7774 - val_loss: 0.7837 - val_acc: 0.6966\n",
      "Epoch 35/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5302 - acc: 0.7827 - val_loss: 0.7849 - val_acc: 0.6961\n",
      "Epoch 36/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5288 - acc: 0.7845 - val_loss: 0.7844 - val_acc: 0.6975\n",
      "Epoch 37/500\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.5289 - acc: 0.7843 - val_loss: 0.7877 - val_acc: 0.6975\n",
      "Epoch 38/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5265 - acc: 0.7825 - val_loss: 0.7896 - val_acc: 0.6974\n",
      "Epoch 39/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5271 - acc: 0.7852\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5271 - acc: 0.7852 - val_loss: 0.7895 - val_acc: 0.6974\n",
      "Epoch 40/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5271 - acc: 0.7848 - val_loss: 0.7901 - val_acc: 0.6973\n",
      "Epoch 41/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5263 - acc: 0.7850 - val_loss: 0.7882 - val_acc: 0.6982\n",
      "Epoch 42/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5254 - acc: 0.7868 - val_loss: 0.7866 - val_acc: 0.6981\n",
      "Epoch 43/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5257 - acc: 0.7843 - val_loss: 0.7904 - val_acc: 0.6968\n",
      "Epoch 44/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5259 - acc: 0.7853\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5258 - acc: 0.7852 - val_loss: 0.7897 - val_acc: 0.6965\n",
      "Epoch 45/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5257 - acc: 0.7849 - val_loss: 0.7882 - val_acc: 0.6969\n",
      "Epoch 46/500\n",
      "133/133 [==============================] - 24s 184ms/step - loss: 0.5260 - acc: 0.7848 - val_loss: 0.7895 - val_acc: 0.6971\n",
      "Epoch 47/500\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.5264 - acc: 0.7839 - val_loss: 0.7898 - val_acc: 0.6970\n",
      "Epoch 48/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5263 - acc: 0.7864 - val_loss: 0.7918 - val_acc: 0.6964\n",
      "Epoch 49/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5257 - acc: 0.7847\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5256 - acc: 0.7850 - val_loss: 0.7887 - val_acc: 0.6970\n",
      "Epoch 50/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5264 - acc: 0.7846 - val_loss: 0.7886 - val_acc: 0.6974\n",
      "Epoch 51/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5275 - acc: 0.7846 - val_loss: 0.7865 - val_acc: 0.6982\n",
      "Epoch 52/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5263 - acc: 0.7858 - val_loss: 0.7892 - val_acc: 0.6967\n",
      "Epoch 53/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5260 - acc: 0.7856 - val_loss: 0.7886 - val_acc: 0.6976\n",
      "Epoch 54/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5270 - acc: 0.7833\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5264 - acc: 0.7836 - val_loss: 0.7897 - val_acc: 0.6968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "133/133 [==============================] - 24s 184ms/step - loss: 0.5265 - acc: 0.7845 - val_loss: 0.7887 - val_acc: 0.6974\n",
      "Epoch 56/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5265 - acc: 0.7841 - val_loss: 0.7894 - val_acc: 0.6971\n",
      "Epoch 57/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5245 - acc: 0.7850 - val_loss: 0.7898 - val_acc: 0.6966\n",
      "Epoch 58/500\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.5248 - acc: 0.7853 - val_loss: 0.7891 - val_acc: 0.6965\n",
      "Epoch 59/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5249 - acc: 0.7872\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.5252 - acc: 0.7870 - val_loss: 0.7919 - val_acc: 0.6962\n",
      "Epoch 60/500\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.5265 - acc: 0.7845 - val_loss: 0.7895 - val_acc: 0.6971\n",
      "Epoch 61/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5247 - acc: 0.7850 - val_loss: 0.7901 - val_acc: 0.6967\n",
      "Epoch 62/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5261 - acc: 0.7855 - val_loss: 0.7880 - val_acc: 0.6974\n",
      "Epoch 63/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5254 - acc: 0.7850 - val_loss: 0.7906 - val_acc: 0.6965\n",
      "Epoch 64/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5243 - acc: 0.7863\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5242 - acc: 0.7862 - val_loss: 0.7904 - val_acc: 0.6966\n",
      "Epoch 65/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5258 - acc: 0.7855 - val_loss: 0.7901 - val_acc: 0.6970\n",
      "Epoch 66/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5265 - acc: 0.7852 - val_loss: 0.7903 - val_acc: 0.6969\n",
      "Epoch 67/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5256 - acc: 0.7852 - val_loss: 0.7893 - val_acc: 0.6968\n",
      "Epoch 68/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5252 - acc: 0.7854 - val_loss: 0.7900 - val_acc: 0.6968\n",
      "Epoch 69/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5255 - acc: 0.7852\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5255 - acc: 0.7850 - val_loss: 0.7903 - val_acc: 0.6966\n",
      "Epoch 70/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5253 - acc: 0.7855 - val_loss: 0.7894 - val_acc: 0.6970\n",
      "Epoch 71/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5261 - acc: 0.7846 - val_loss: 0.7875 - val_acc: 0.6979\n",
      "Epoch 72/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5263 - acc: 0.7854 - val_loss: 0.7878 - val_acc: 0.6980\n",
      "Epoch 73/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5252 - acc: 0.7846 - val_loss: 0.7878 - val_acc: 0.6976\n",
      "Epoch 74/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5239 - acc: 0.7853\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5243 - acc: 0.7849 - val_loss: 0.7897 - val_acc: 0.6966\n",
      "Epoch 75/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5246 - acc: 0.7845 - val_loss: 0.7895 - val_acc: 0.6969\n",
      "Epoch 76/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5281 - acc: 0.7840 - val_loss: 0.7896 - val_acc: 0.6972\n",
      "Epoch 77/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5254 - acc: 0.7847 - val_loss: 0.7904 - val_acc: 0.6970\n",
      "Epoch 78/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5257 - acc: 0.7853 - val_loss: 0.7900 - val_acc: 0.6967\n",
      "Epoch 79/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5267 - acc: 0.7846\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5263 - acc: 0.7847 - val_loss: 0.7906 - val_acc: 0.6964\n",
      "Epoch 80/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5261 - acc: 0.7845 - val_loss: 0.7912 - val_acc: 0.6958\n",
      "Epoch 81/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5283 - acc: 0.7846 - val_loss: 0.7899 - val_acc: 0.6974\n",
      "Epoch 82/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5275 - acc: 0.7863 - val_loss: 0.7887 - val_acc: 0.6971\n",
      "Epoch 83/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5265 - acc: 0.7847 - val_loss: 0.7919 - val_acc: 0.6959\n",
      "Epoch 84/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5258 - acc: 0.7856\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5261 - acc: 0.7855 - val_loss: 0.7914 - val_acc: 0.6959\n",
      "Epoch 85/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5269 - acc: 0.7848 - val_loss: 0.7904 - val_acc: 0.6969\n",
      "Epoch 86/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5280 - acc: 0.7854 - val_loss: 0.7891 - val_acc: 0.6971\n",
      "Epoch 87/500\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.5256 - acc: 0.7842 - val_loss: 0.7879 - val_acc: 0.6974\n",
      "Epoch 88/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5258 - acc: 0.7858 - val_loss: 0.7902 - val_acc: 0.6968\n",
      "Epoch 89/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5259 - acc: 0.7845\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5264 - acc: 0.7843 - val_loss: 0.7895 - val_acc: 0.6970\n",
      "Epoch 90/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5253 - acc: 0.7831 - val_loss: 0.7908 - val_acc: 0.6962\n",
      "Epoch 91/500\n",
      "133/133 [==============================] - 24s 178ms/step - loss: 0.5266 - acc: 0.7822 - val_loss: 0.7900 - val_acc: 0.6965\n",
      "Epoch 92/500\n",
      "133/133 [==============================] - 24s 177ms/step - loss: 0.5271 - acc: 0.7850 - val_loss: 0.7906 - val_acc: 0.6966\n",
      "Epoch 93/500\n",
      "133/133 [==============================] - 24s 177ms/step - loss: 0.5248 - acc: 0.7852 - val_loss: 0.7909 - val_acc: 0.6963\n",
      "Epoch 94/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5261 - acc: 0.7858\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5260 - acc: 0.7859 - val_loss: 0.7881 - val_acc: 0.6973\n",
      "Epoch 95/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5267 - acc: 0.7831 - val_loss: 0.7891 - val_acc: 0.6966\n",
      "Epoch 96/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5266 - acc: 0.7828 - val_loss: 0.7899 - val_acc: 0.6969\n",
      "Epoch 97/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5274 - acc: 0.7827 - val_loss: 0.7908 - val_acc: 0.6958\n",
      "Epoch 98/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5272 - acc: 0.7831 - val_loss: 0.7909 - val_acc: 0.6970\n",
      "Epoch 99/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5252 - acc: 0.7857\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5256 - acc: 0.7854 - val_loss: 0.7892 - val_acc: 0.6965\n",
      "Epoch 100/500\n",
      "133/133 [==============================] - 24s 178ms/step - loss: 0.5249 - acc: 0.7847 - val_loss: 0.7905 - val_acc: 0.6966\n",
      "Epoch 101/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5249 - acc: 0.7850 - val_loss: 0.7890 - val_acc: 0.6974\n",
      "Epoch 102/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5254 - acc: 0.7857 - val_loss: 0.7902 - val_acc: 0.6968\n",
      "Epoch 103/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5264 - acc: 0.7859 - val_loss: 0.7884 - val_acc: 0.6975\n",
      "Epoch 104/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5248 - acc: 0.7854\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5247 - acc: 0.7853 - val_loss: 0.7913 - val_acc: 0.6963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5238 - acc: 0.7882 - val_loss: 0.7907 - val_acc: 0.6964\n",
      "Epoch 106/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5248 - acc: 0.7850 - val_loss: 0.7899 - val_acc: 0.6965\n",
      "Epoch 107/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5253 - acc: 0.7852 - val_loss: 0.7904 - val_acc: 0.6966\n",
      "Epoch 108/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5262 - acc: 0.7833 - val_loss: 0.7901 - val_acc: 0.6968\n",
      "Epoch 109/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5257 - acc: 0.7846\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5259 - acc: 0.7845 - val_loss: 0.7880 - val_acc: 0.6975\n",
      "Epoch 110/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5263 - acc: 0.7877 - val_loss: 0.7892 - val_acc: 0.6979\n",
      "Epoch 111/500\n",
      "133/133 [==============================] - 24s 178ms/step - loss: 0.5258 - acc: 0.7850 - val_loss: 0.7906 - val_acc: 0.6966\n",
      "Epoch 112/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5262 - acc: 0.7854 - val_loss: 0.7899 - val_acc: 0.6968\n",
      "Epoch 113/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5262 - acc: 0.7849 - val_loss: 0.7903 - val_acc: 0.6971\n",
      "Epoch 114/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5264 - acc: 0.7842\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5263 - acc: 0.7842 - val_loss: 0.7878 - val_acc: 0.6976\n",
      "Epoch 115/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5262 - acc: 0.7857 - val_loss: 0.7916 - val_acc: 0.6961\n",
      "Epoch 116/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5257 - acc: 0.7843 - val_loss: 0.7902 - val_acc: 0.6966\n",
      "Epoch 117/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5257 - acc: 0.7854 - val_loss: 0.7907 - val_acc: 0.6961\n",
      "Epoch 118/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5253 - acc: 0.7828 - val_loss: 0.7892 - val_acc: 0.6972\n",
      "Epoch 119/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5261 - acc: 0.7844\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5263 - acc: 0.7842 - val_loss: 0.7896 - val_acc: 0.6971\n",
      "Epoch 120/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5278 - acc: 0.7836 - val_loss: 0.7902 - val_acc: 0.6971\n",
      "Epoch 121/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5256 - acc: 0.7846 - val_loss: 0.7903 - val_acc: 0.6973\n",
      "Epoch 122/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5260 - acc: 0.7852 - val_loss: 0.7885 - val_acc: 0.6973\n",
      "Epoch 123/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5272 - acc: 0.7849 - val_loss: 0.7928 - val_acc: 0.6961\n",
      "Epoch 124/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5267 - acc: 0.7847\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5262 - acc: 0.7850 - val_loss: 0.7895 - val_acc: 0.6972\n",
      "Epoch 125/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5256 - acc: 0.7852 - val_loss: 0.7898 - val_acc: 0.6972\n",
      "Epoch 126/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5270 - acc: 0.7836 - val_loss: 0.7905 - val_acc: 0.6972\n",
      "Epoch 127/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5257 - acc: 0.7851 - val_loss: 0.7909 - val_acc: 0.6970\n",
      "Epoch 128/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5257 - acc: 0.7851 - val_loss: 0.7900 - val_acc: 0.6971\n",
      "Epoch 129/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5254 - acc: 0.7853\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5255 - acc: 0.7851 - val_loss: 0.7909 - val_acc: 0.6966\n",
      "Epoch 130/500\n",
      "133/133 [==============================] - 24s 178ms/step - loss: 0.5260 - acc: 0.7867 - val_loss: 0.7892 - val_acc: 0.6971\n",
      "Epoch 131/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5262 - acc: 0.7846 - val_loss: 0.7899 - val_acc: 0.6970\n",
      "Epoch 132/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5258 - acc: 0.7855 - val_loss: 0.7921 - val_acc: 0.6966\n",
      "Epoch 133/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5270 - acc: 0.7839 - val_loss: 0.7881 - val_acc: 0.6974\n",
      "Epoch 134/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5246 - acc: 0.7846\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5243 - acc: 0.7845 - val_loss: 0.7926 - val_acc: 0.6960\n",
      "Epoch 135/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5254 - acc: 0.7848 - val_loss: 0.7904 - val_acc: 0.6966\n",
      "Epoch 136/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5250 - acc: 0.7849 - val_loss: 0.7912 - val_acc: 0.6968\n",
      "Epoch 137/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5246 - acc: 0.7847 - val_loss: 0.7904 - val_acc: 0.6970\n",
      "Epoch 138/500\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.5260 - acc: 0.7852 - val_loss: 0.7910 - val_acc: 0.6962\n",
      "Epoch 139/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5258 - acc: 0.7843\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5262 - acc: 0.7842 - val_loss: 0.7913 - val_acc: 0.6965\n",
      "Epoch 140/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5264 - acc: 0.7846 - val_loss: 0.7894 - val_acc: 0.6974\n",
      "Epoch 141/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5243 - acc: 0.7869 - val_loss: 0.7906 - val_acc: 0.6974\n",
      "Epoch 142/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5260 - acc: 0.7850 - val_loss: 0.7903 - val_acc: 0.6969\n",
      "Epoch 143/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5254 - acc: 0.7845 - val_loss: 0.7893 - val_acc: 0.6972\n",
      "Epoch 144/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5267 - acc: 0.7845\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5264 - acc: 0.7847 - val_loss: 0.7917 - val_acc: 0.6966\n",
      "Epoch 145/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5258 - acc: 0.7850 - val_loss: 0.7905 - val_acc: 0.6971\n",
      "Epoch 146/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5267 - acc: 0.7851 - val_loss: 0.7913 - val_acc: 0.6966\n",
      "Epoch 147/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5252 - acc: 0.7851 - val_loss: 0.7903 - val_acc: 0.6962\n",
      "Epoch 148/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5258 - acc: 0.7872 - val_loss: 0.7907 - val_acc: 0.6963\n",
      "Epoch 149/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5269 - acc: 0.7853\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5269 - acc: 0.7854 - val_loss: 0.7894 - val_acc: 0.6971\n",
      "Epoch 150/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5251 - acc: 0.7845 - val_loss: 0.7900 - val_acc: 0.6968\n",
      "Epoch 151/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5257 - acc: 0.7844 - val_loss: 0.7916 - val_acc: 0.6966\n",
      "Epoch 152/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5263 - acc: 0.7841 - val_loss: 0.7904 - val_acc: 0.6970\n",
      "Epoch 153/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5254 - acc: 0.7864 - val_loss: 0.7900 - val_acc: 0.6966\n",
      "Epoch 154/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5259 - acc: 0.7868\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5259 - acc: 0.7869 - val_loss: 0.7904 - val_acc: 0.6965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5239 - acc: 0.7874 - val_loss: 0.7912 - val_acc: 0.6965\n",
      "Epoch 156/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5267 - acc: 0.7850 - val_loss: 0.7907 - val_acc: 0.6962\n",
      "Epoch 157/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5267 - acc: 0.7851 - val_loss: 0.7903 - val_acc: 0.6968\n",
      "Epoch 158/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5249 - acc: 0.7861 - val_loss: 0.7925 - val_acc: 0.6959\n",
      "Epoch 159/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5249 - acc: 0.7844\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 178ms/step - loss: 0.5250 - acc: 0.7842 - val_loss: 0.7904 - val_acc: 0.6965\n",
      "Epoch 160/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5232 - acc: 0.7856 - val_loss: 0.7911 - val_acc: 0.6969\n",
      "Epoch 161/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5257 - acc: 0.7855 - val_loss: 0.7900 - val_acc: 0.6967\n",
      "Epoch 162/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5259 - acc: 0.7856 - val_loss: 0.7897 - val_acc: 0.6969\n",
      "Epoch 163/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5251 - acc: 0.7843 - val_loss: 0.7905 - val_acc: 0.6965\n",
      "Epoch 164/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5240 - acc: 0.7853\n",
      "Epoch 00164: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5242 - acc: 0.7851 - val_loss: 0.7907 - val_acc: 0.6966\n",
      "Epoch 165/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5259 - acc: 0.7846 - val_loss: 0.7908 - val_acc: 0.6968\n",
      "Epoch 166/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5238 - acc: 0.7840 - val_loss: 0.7898 - val_acc: 0.6969\n",
      "Epoch 167/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5255 - acc: 0.7850 - val_loss: 0.7917 - val_acc: 0.6966\n",
      "Epoch 168/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5260 - acc: 0.7855 - val_loss: 0.7880 - val_acc: 0.6974\n",
      "Epoch 169/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5251 - acc: 0.7843\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5248 - acc: 0.7845 - val_loss: 0.7919 - val_acc: 0.6959\n",
      "Epoch 170/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5237 - acc: 0.7866 - val_loss: 0.7928 - val_acc: 0.6961\n",
      "Epoch 171/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5253 - acc: 0.7851 - val_loss: 0.7898 - val_acc: 0.6972\n",
      "Epoch 172/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5256 - acc: 0.7862 - val_loss: 0.7914 - val_acc: 0.6966\n",
      "Epoch 173/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5235 - acc: 0.7853 - val_loss: 0.7912 - val_acc: 0.6959\n",
      "Epoch 174/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5239 - acc: 0.7854\n",
      "Epoch 00174: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5242 - acc: 0.7854 - val_loss: 0.7908 - val_acc: 0.6964\n",
      "Epoch 175/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5267 - acc: 0.7830 - val_loss: 0.7895 - val_acc: 0.6967\n",
      "Epoch 176/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5258 - acc: 0.7846 - val_loss: 0.7898 - val_acc: 0.6969\n",
      "Epoch 177/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5263 - acc: 0.7846 - val_loss: 0.7903 - val_acc: 0.6969\n",
      "Epoch 178/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5268 - acc: 0.7835 - val_loss: 0.7907 - val_acc: 0.6970\n",
      "Epoch 179/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5243 - acc: 0.7843\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5246 - acc: 0.7839 - val_loss: 0.7914 - val_acc: 0.6964\n",
      "Epoch 180/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5267 - acc: 0.7845 - val_loss: 0.7903 - val_acc: 0.6967\n",
      "Epoch 181/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5244 - acc: 0.7866 - val_loss: 0.7903 - val_acc: 0.6966\n",
      "Epoch 182/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5261 - acc: 0.7843 - val_loss: 0.7898 - val_acc: 0.6970\n",
      "Epoch 183/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5248 - acc: 0.7846 - val_loss: 0.7911 - val_acc: 0.6963\n",
      "Epoch 184/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5257 - acc: 0.7855\n",
      "Epoch 00184: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5259 - acc: 0.7853 - val_loss: 0.7887 - val_acc: 0.6969\n",
      "Epoch 185/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5268 - acc: 0.7841 - val_loss: 0.7902 - val_acc: 0.6966\n",
      "Epoch 186/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5277 - acc: 0.7852 - val_loss: 0.7920 - val_acc: 0.6961\n",
      "Epoch 187/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5250 - acc: 0.7842 - val_loss: 0.7896 - val_acc: 0.6971\n",
      "Epoch 188/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5238 - acc: 0.7859 - val_loss: 0.7902 - val_acc: 0.6966\n",
      "Epoch 189/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5253 - acc: 0.7866\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5257 - acc: 0.7866 - val_loss: 0.7906 - val_acc: 0.6962\n",
      "Epoch 190/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5242 - acc: 0.7878 - val_loss: 0.7899 - val_acc: 0.6968\n",
      "Epoch 191/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5257 - acc: 0.7854 - val_loss: 0.7906 - val_acc: 0.6965\n",
      "Epoch 192/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5263 - acc: 0.7849 - val_loss: 0.7915 - val_acc: 0.6965\n",
      "Epoch 193/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5256 - acc: 0.7851 - val_loss: 0.7920 - val_acc: 0.6964\n",
      "Epoch 194/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5246 - acc: 0.7853\n",
      "Epoch 00194: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.5242 - acc: 0.7856 - val_loss: 0.7898 - val_acc: 0.6966\n",
      "Epoch 195/500\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.5249 - acc: 0.7862 - val_loss: 0.7923 - val_acc: 0.6963\n",
      "Epoch 196/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5254 - acc: 0.7839 - val_loss: 0.7904 - val_acc: 0.6966\n",
      "Epoch 197/500\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.5248 - acc: 0.7857 - val_loss: 0.7912 - val_acc: 0.6959\n",
      "Epoch 198/500\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.5260 - acc: 0.7832 - val_loss: 0.7902 - val_acc: 0.6964\n",
      "Epoch 199/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5273 - acc: 0.7851\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5274 - acc: 0.7850 - val_loss: 0.7910 - val_acc: 0.6966\n",
      "Epoch 200/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5232 - acc: 0.7872 - val_loss: 0.7921 - val_acc: 0.6958\n",
      "Epoch 201/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5259 - acc: 0.7842 - val_loss: 0.7900 - val_acc: 0.6967\n",
      "Epoch 202/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5279 - acc: 0.7838 - val_loss: 0.7919 - val_acc: 0.6958\n",
      "Epoch 203/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5272 - acc: 0.7842 - val_loss: 0.7915 - val_acc: 0.6959\n",
      "Epoch 204/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5252 - acc: 0.7856\n",
      "Epoch 00204: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5254 - acc: 0.7854 - val_loss: 0.7918 - val_acc: 0.6961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5257 - acc: 0.7856 - val_loss: 0.7920 - val_acc: 0.6956\n",
      "Epoch 206/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5252 - acc: 0.7843 - val_loss: 0.7907 - val_acc: 0.6963\n",
      "Epoch 207/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5252 - acc: 0.7854 - val_loss: 0.7935 - val_acc: 0.6952\n",
      "Epoch 208/500\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.5245 - acc: 0.7849 - val_loss: 0.7905 - val_acc: 0.6962\n",
      "Epoch 209/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5243 - acc: 0.7854\n",
      "Epoch 00209: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5242 - acc: 0.7853 - val_loss: 0.7909 - val_acc: 0.6962\n",
      "Epoch 210/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5236 - acc: 0.7842 - val_loss: 0.7908 - val_acc: 0.6962\n",
      "Epoch 211/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5257 - acc: 0.7838 - val_loss: 0.7933 - val_acc: 0.6957\n",
      "Epoch 212/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5256 - acc: 0.7851 - val_loss: 0.7917 - val_acc: 0.6964\n",
      "Epoch 213/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5256 - acc: 0.7845 - val_loss: 0.7917 - val_acc: 0.6962\n",
      "Epoch 214/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5255 - acc: 0.7868\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5257 - acc: 0.7866 - val_loss: 0.7918 - val_acc: 0.6956\n",
      "Epoch 215/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5261 - acc: 0.7852 - val_loss: 0.7897 - val_acc: 0.6967\n",
      "Epoch 216/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5248 - acc: 0.7860 - val_loss: 0.7895 - val_acc: 0.6964\n",
      "Epoch 217/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5246 - acc: 0.7854 - val_loss: 0.7914 - val_acc: 0.6958\n",
      "Epoch 218/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5251 - acc: 0.7870 - val_loss: 0.7914 - val_acc: 0.6962\n",
      "Epoch 219/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5239 - acc: 0.7852\n",
      "Epoch 00219: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5239 - acc: 0.7853 - val_loss: 0.7905 - val_acc: 0.6958\n",
      "Epoch 220/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5245 - acc: 0.7857 - val_loss: 0.7909 - val_acc: 0.6960\n",
      "Epoch 221/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5258 - acc: 0.7848 - val_loss: 0.7917 - val_acc: 0.6957\n",
      "Epoch 222/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5246 - acc: 0.7856 - val_loss: 0.7916 - val_acc: 0.6957\n",
      "Epoch 223/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5236 - acc: 0.7843 - val_loss: 0.7904 - val_acc: 0.6963\n",
      "Epoch 224/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5250 - acc: 0.7862\n",
      "Epoch 00224: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5255 - acc: 0.7860 - val_loss: 0.7915 - val_acc: 0.6956\n",
      "Epoch 225/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5250 - acc: 0.7853 - val_loss: 0.7920 - val_acc: 0.6957\n",
      "Epoch 226/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5265 - acc: 0.7848 - val_loss: 0.7901 - val_acc: 0.6966\n",
      "Epoch 227/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5254 - acc: 0.7857 - val_loss: 0.7910 - val_acc: 0.6964\n",
      "Epoch 228/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5251 - acc: 0.7848 - val_loss: 0.7896 - val_acc: 0.6972\n",
      "Epoch 229/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5247 - acc: 0.7847\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5242 - acc: 0.7850 - val_loss: 0.7927 - val_acc: 0.6956\n",
      "Epoch 230/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5232 - acc: 0.7865 - val_loss: 0.7922 - val_acc: 0.6958\n",
      "Epoch 231/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5252 - acc: 0.7857 - val_loss: 0.7910 - val_acc: 0.6968\n",
      "Epoch 232/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5247 - acc: 0.7858 - val_loss: 0.7906 - val_acc: 0.6969\n",
      "Epoch 233/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5260 - acc: 0.7836 - val_loss: 0.7905 - val_acc: 0.6965\n",
      "Epoch 234/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5245 - acc: 0.7840\n",
      "Epoch 00234: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5243 - acc: 0.7841 - val_loss: 0.7899 - val_acc: 0.6973\n",
      "Epoch 235/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5243 - acc: 0.7869 - val_loss: 0.7894 - val_acc: 0.6968\n",
      "Epoch 236/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5252 - acc: 0.7845 - val_loss: 0.7913 - val_acc: 0.6972\n",
      "Epoch 237/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5253 - acc: 0.7850 - val_loss: 0.7920 - val_acc: 0.6962\n",
      "Epoch 238/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5234 - acc: 0.7872 - val_loss: 0.7916 - val_acc: 0.6960\n",
      "Epoch 239/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5260 - acc: 0.7857\n",
      "Epoch 00239: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 183ms/step - loss: 0.5262 - acc: 0.7857 - val_loss: 0.7903 - val_acc: 0.6966\n",
      "Epoch 240/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5253 - acc: 0.7851 - val_loss: 0.7887 - val_acc: 0.6973\n",
      "Epoch 241/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5241 - acc: 0.7848 - val_loss: 0.7920 - val_acc: 0.6958\n",
      "Epoch 242/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5254 - acc: 0.7844 - val_loss: 0.7901 - val_acc: 0.6964\n",
      "Epoch 243/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5230 - acc: 0.7875 - val_loss: 0.7914 - val_acc: 0.6964\n",
      "Epoch 244/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5258 - acc: 0.7850\n",
      "Epoch 00244: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5259 - acc: 0.7850 - val_loss: 0.7924 - val_acc: 0.6960\n",
      "Epoch 245/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5232 - acc: 0.7858 - val_loss: 0.7885 - val_acc: 0.6968\n",
      "Epoch 246/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5274 - acc: 0.7841 - val_loss: 0.7910 - val_acc: 0.6966\n",
      "Epoch 247/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5247 - acc: 0.7857 - val_loss: 0.7917 - val_acc: 0.6960\n",
      "Epoch 248/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5259 - acc: 0.7831 - val_loss: 0.7927 - val_acc: 0.6953\n",
      "Epoch 249/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5252 - acc: 0.7865\n",
      "Epoch 00249: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5255 - acc: 0.7865 - val_loss: 0.7903 - val_acc: 0.6968\n",
      "Epoch 250/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5249 - acc: 0.7849 - val_loss: 0.7913 - val_acc: 0.6963\n",
      "Epoch 251/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5261 - acc: 0.7851 - val_loss: 0.7931 - val_acc: 0.6955\n",
      "Epoch 252/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5254 - acc: 0.7853 - val_loss: 0.7928 - val_acc: 0.6961\n",
      "Epoch 253/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5249 - acc: 0.7846 - val_loss: 0.7917 - val_acc: 0.6966\n",
      "Epoch 254/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5253 - acc: 0.7852\n",
      "Epoch 00254: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5252 - acc: 0.7855 - val_loss: 0.7922 - val_acc: 0.6961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5264 - acc: 0.7827 - val_loss: 0.7915 - val_acc: 0.6961\n",
      "Epoch 256/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5262 - acc: 0.7852 - val_loss: 0.7921 - val_acc: 0.6965\n",
      "Epoch 257/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5233 - acc: 0.7859 - val_loss: 0.7906 - val_acc: 0.6966\n",
      "Epoch 258/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5245 - acc: 0.7852 - val_loss: 0.7905 - val_acc: 0.6965\n",
      "Epoch 259/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5257 - acc: 0.7868\n",
      "Epoch 00259: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5256 - acc: 0.7868 - val_loss: 0.7901 - val_acc: 0.6968\n",
      "Epoch 260/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5255 - acc: 0.7838 - val_loss: 0.7916 - val_acc: 0.6958\n",
      "Epoch 261/500\n",
      "133/133 [==============================] - 24s 179ms/step - loss: 0.5255 - acc: 0.7852 - val_loss: 0.7912 - val_acc: 0.6966\n",
      "Epoch 262/500\n",
      "133/133 [==============================] - 24s 180ms/step - loss: 0.5245 - acc: 0.7867 - val_loss: 0.7923 - val_acc: 0.6958\n",
      "Epoch 263/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5238 - acc: 0.7860 - val_loss: 0.7933 - val_acc: 0.6959\n",
      "Epoch 264/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5239 - acc: 0.7854\n",
      "Epoch 00264: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5245 - acc: 0.7851 - val_loss: 0.7916 - val_acc: 0.6958\n",
      "Epoch 265/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5243 - acc: 0.7846 - val_loss: 0.7910 - val_acc: 0.6961\n",
      "Epoch 266/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5259 - acc: 0.7844 - val_loss: 0.7914 - val_acc: 0.6958\n",
      "Epoch 267/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5245 - acc: 0.7845 - val_loss: 0.7903 - val_acc: 0.6966\n",
      "Epoch 268/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5256 - acc: 0.7841 - val_loss: 0.7936 - val_acc: 0.6956\n",
      "Epoch 269/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5241 - acc: 0.7848\n",
      "Epoch 00269: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5244 - acc: 0.7846 - val_loss: 0.7899 - val_acc: 0.6959\n",
      "Epoch 270/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5253 - acc: 0.7859 - val_loss: 0.7928 - val_acc: 0.6952\n",
      "Epoch 271/500\n",
      "133/133 [==============================] - 24s 182ms/step - loss: 0.5252 - acc: 0.7845 - val_loss: 0.7912 - val_acc: 0.6963\n",
      "Epoch 272/500\n",
      "133/133 [==============================] - 24s 181ms/step - loss: 0.5256 - acc: 0.7847 - val_loss: 0.7926 - val_acc: 0.6959\n",
      "Epoch 273/500\n",
      "132/133 [============================>.] - ETA: 0s - loss: 0.5248 - acc: 0.7852"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b8111761ec15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredonplat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m           \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator)\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dl4cv/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h = model.fit_generator(train_it, epochs=500, validation_data=test_it, callbacks=[tb,ch, redonplat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RT - 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/X_train_10.csv\", header=None)\n",
    "X_test = pd.read_csv(\"data/X_test_10.csv\", header=None)\n",
    "\n",
    "Y = np.load(\"data/Y_RT_10.npy\")\n",
    "Y = to_categorical(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.flatten()\n",
    "X_test = X_test.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22201,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_it = DataGenerator('data/RT_10_data', X_train, Y, (64, 500), num_classes=3, batch_size=256)\n",
    "\n",
    "test_it = DataGenerator('data/RT_10_data', X_test, Y, (64, 500), num_classes=3, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 500, 64)]         0         \n",
      "_________________________________________________________________\n",
      "model (Model)                (None, 54, 64)            35872     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 54, 200)           132000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 54, 200)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 54, 200)           240800    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 32403     \n",
      "=================================================================\n",
      "Total params: 441,075\n",
      "Trainable params: 441,075\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model_lstm()\n",
    "\n",
    "tb = TensorBoard(log_dir=\"Tensorboard\")\n",
    "ch = ModelCheckpoint(\"models/t-vgg_mod_rt_10_2.h5\", monitor='val_acc', save_best_only=True, mode='max')\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=2, min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "86/86 [==============================] - 23s 268ms/step - loss: 1.0391 - acc: 0.4577 - val_loss: 0.9466 - val_acc: 0.5509\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 22s 250ms/step - loss: 0.9220 - acc: 0.5651 - val_loss: 0.8869 - val_acc: 0.5903\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 21s 249ms/step - loss: 0.8594 - acc: 0.6097 - val_loss: 0.8406 - val_acc: 0.6246\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 22s 258ms/step - loss: 0.8137 - acc: 0.6332 - val_loss: 0.8222 - val_acc: 0.6339\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.7864 - acc: 0.6519 - val_loss: 0.7838 - val_acc: 0.6579\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 21s 249ms/step - loss: 0.7552 - acc: 0.6669 - val_loss: 0.7878 - val_acc: 0.6540\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.7219 - acc: 0.6872 - val_loss: 0.7390 - val_acc: 0.6789\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 22s 256ms/step - loss: 0.6913 - acc: 0.7021 - val_loss: 0.7454 - val_acc: 0.6879\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 22s 256ms/step - loss: 0.6670 - acc: 0.7148 - val_loss: 0.7035 - val_acc: 0.7012\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 21s 250ms/step - loss: 0.6379 - acc: 0.7320 - val_loss: 0.7069 - val_acc: 0.7003\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 21s 249ms/step - loss: 0.6194 - acc: 0.7424 - val_loss: 0.6922 - val_acc: 0.7146\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.5988 - acc: 0.7470 - val_loss: 0.6732 - val_acc: 0.7147\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.5840 - acc: 0.7584 - val_loss: 0.6732 - val_acc: 0.7121\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.5490 - acc: 0.7748 - val_loss: 0.6629 - val_acc: 0.7247\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.5316 - acc: 0.7837 - val_loss: 0.6600 - val_acc: 0.7305\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 22s 250ms/step - loss: 0.5074 - acc: 0.7934 - val_loss: 0.6696 - val_acc: 0.7327\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 22s 253ms/step - loss: 0.5005 - acc: 0.7979 - val_loss: 0.6418 - val_acc: 0.7387\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 21s 250ms/step - loss: 0.4732 - acc: 0.8109 - val_loss: 0.6352 - val_acc: 0.7447\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 22s 250ms/step - loss: 0.4560 - acc: 0.8129 - val_loss: 0.6545 - val_acc: 0.7441\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.4375 - acc: 0.8235 - val_loss: 0.6279 - val_acc: 0.7527\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 22s 250ms/step - loss: 0.4243 - acc: 0.8286 - val_loss: 0.6406 - val_acc: 0.7527\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 22s 258ms/step - loss: 0.4032 - acc: 0.8391 - val_loss: 0.6537 - val_acc: 0.7472\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.3855 - acc: 0.8468 - val_loss: 0.6745 - val_acc: 0.7524\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 22s 258ms/step - loss: 0.3649 - acc: 0.8551 - val_loss: 0.6373 - val_acc: 0.7559\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.3441 - acc: 0.8648 - val_loss: 0.6719 - val_acc: 0.7571\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 21s 250ms/step - loss: 0.3342 - acc: 0.8683 - val_loss: 0.6719 - val_acc: 0.7550\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.3117 - acc: 0.8775 - val_loss: 0.6678 - val_acc: 0.7552\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 22s 254ms/step - loss: 0.2943 - acc: 0.8850 - val_loss: 0.7026 - val_acc: 0.7673\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 22s 252ms/step - loss: 0.2705 - acc: 0.8945 - val_loss: 0.6960 - val_acc: 0.7680\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 22s 250ms/step - loss: 0.2668 - acc: 0.8956 - val_loss: 0.7154 - val_acc: 0.7683\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 22s 256ms/step - loss: 0.2452 - acc: 0.9057 - val_loss: 0.7422 - val_acc: 0.7681\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.2480 - acc: 0.9055 - val_loss: 0.7341 - val_acc: 0.7642\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 22s 250ms/step - loss: 0.2254 - acc: 0.9129 - val_loss: 0.7516 - val_acc: 0.7706\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 22s 255ms/step - loss: 0.2122 - acc: 0.9201 - val_loss: 0.7782 - val_acc: 0.7596\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 21s 250ms/step - loss: 0.2012 - acc: 0.9248 - val_loss: 0.7647 - val_acc: 0.7673\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 22s 252ms/step - loss: 0.2024 - acc: 0.9253 - val_loss: 0.7785 - val_acc: 0.7645\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 21s 248ms/step - loss: 0.1860 - acc: 0.9298 - val_loss: 0.7657 - val_acc: 0.7719\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.1756 - acc: 0.9350 - val_loss: 0.8361 - val_acc: 0.7684\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 22s 254ms/step - loss: 0.1714 - acc: 0.9367 - val_loss: 0.8437 - val_acc: 0.7628\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 22s 258ms/step - loss: 0.1550 - acc: 0.9420 - val_loss: 0.8514 - val_acc: 0.7694\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 22s 258ms/step - loss: 0.1522 - acc: 0.9451 - val_loss: 0.8700 - val_acc: 0.7686\n",
      "Epoch 42/100\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.1473 - acc: 0.9469\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.1470 - acc: 0.9470 - val_loss: 0.9026 - val_acc: 0.7600\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 22s 256ms/step - loss: 0.0933 - acc: 0.9689 - val_loss: 0.8514 - val_acc: 0.7771\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 22s 252ms/step - loss: 0.0623 - acc: 0.9809 - val_loss: 0.8497 - val_acc: 0.7819\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 21s 250ms/step - loss: 0.0564 - acc: 0.9836 - val_loss: 0.8694 - val_acc: 0.7806\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.0545 - acc: 0.9834 - val_loss: 0.8706 - val_acc: 0.7819\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 22s 258ms/step - loss: 0.0534 - acc: 0.9847 - val_loss: 0.8748 - val_acc: 0.7836\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 22s 256ms/step - loss: 0.0464 - acc: 0.9862 - val_loss: 0.8817 - val_acc: 0.7828\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 22s 256ms/step - loss: 0.0480 - acc: 0.9861 - val_loss: 0.8969 - val_acc: 0.7796\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 21s 242ms/step - loss: 0.0480 - acc: 0.9870 - val_loss: 0.8950 - val_acc: 0.7818\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.0444 - acc: 0.9868 - val_loss: 0.8936 - val_acc: 0.7826\n",
      "Epoch 52/100\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9874\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.0434 - acc: 0.9874 - val_loss: 0.9042 - val_acc: 0.7782\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 22s 258ms/step - loss: 0.0427 - acc: 0.9877 - val_loss: 0.9043 - val_acc: 0.7819\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 22s 250ms/step - loss: 0.0392 - acc: 0.9890 - val_loss: 0.8999 - val_acc: 0.7797\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.0415 - acc: 0.9882 - val_loss: 0.9064 - val_acc: 0.7803\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.0443 - acc: 0.9880 - val_loss: 0.8995 - val_acc: 0.7817\n",
      "Epoch 57/100\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9878\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "86/86 [==============================] - 22s 258ms/step - loss: 0.0422 - acc: 0.9879 - val_loss: 0.9069 - val_acc: 0.7812\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.0415 - acc: 0.9889 - val_loss: 0.9049 - val_acc: 0.7824\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 22s 258ms/step - loss: 0.0419 - acc: 0.9890 - val_loss: 0.9042 - val_acc: 0.7825\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 21s 250ms/step - loss: 0.0398 - acc: 0.9891 - val_loss: 0.8971 - val_acc: 0.7826\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.0372 - acc: 0.9900 - val_loss: 0.9058 - val_acc: 0.7817\n",
      "Epoch 62/100\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9882\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "86/86 [==============================] - 22s 252ms/step - loss: 0.0420 - acc: 0.9882 - val_loss: 0.9064 - val_acc: 0.7821\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 22s 250ms/step - loss: 0.0396 - acc: 0.9884 - val_loss: 0.8960 - val_acc: 0.7829\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 22s 250ms/step - loss: 0.0415 - acc: 0.9880 - val_loss: 0.9046 - val_acc: 0.7812\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 22s 256ms/step - loss: 0.0351 - acc: 0.9906 - val_loss: 0.9079 - val_acc: 0.7819\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 22s 256ms/step - loss: 0.0411 - acc: 0.9876 - val_loss: 0.9053 - val_acc: 0.7821\n",
      "Epoch 67/100\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9884\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "86/86 [==============================] - 22s 256ms/step - loss: 0.0407 - acc: 0.9884 - val_loss: 0.9070 - val_acc: 0.7825\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.0398 - acc: 0.9891 - val_loss: 0.9047 - val_acc: 0.7814\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.0411 - acc: 0.9891 - val_loss: 0.9061 - val_acc: 0.7818\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 22s 258ms/step - loss: 0.0410 - acc: 0.9885 - val_loss: 0.9034 - val_acc: 0.7817\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 22s 250ms/step - loss: 0.0384 - acc: 0.9889 - val_loss: 0.8981 - val_acc: 0.7826\n",
      "Epoch 72/100\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9878\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "86/86 [==============================] - 22s 253ms/step - loss: 0.0406 - acc: 0.9878 - val_loss: 0.9114 - val_acc: 0.7821\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.0395 - acc: 0.9893 - val_loss: 0.9051 - val_acc: 0.7825\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.0420 - acc: 0.9883 - val_loss: 0.9056 - val_acc: 0.7824\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.0415 - acc: 0.9887 - val_loss: 0.9075 - val_acc: 0.7815\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.0392 - acc: 0.9896 - val_loss: 0.9073 - val_acc: 0.7828\n",
      "Epoch 77/100\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9895\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "86/86 [==============================] - 21s 250ms/step - loss: 0.0390 - acc: 0.9895 - val_loss: 0.9064 - val_acc: 0.7825\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.0399 - acc: 0.9898 - val_loss: 0.9062 - val_acc: 0.7818\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 22s 258ms/step - loss: 0.0389 - acc: 0.9887 - val_loss: 0.9136 - val_acc: 0.7807\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 21s 250ms/step - loss: 0.0439 - acc: 0.9882 - val_loss: 0.9011 - val_acc: 0.7824\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.0407 - acc: 0.9888 - val_loss: 0.9045 - val_acc: 0.7824\n",
      "Epoch 82/100\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9878\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.0403 - acc: 0.9879 - val_loss: 0.9097 - val_acc: 0.7825\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 22s 256ms/step - loss: 0.0399 - acc: 0.9900 - val_loss: 0.8999 - val_acc: 0.7829\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.0440 - acc: 0.9881 - val_loss: 0.9041 - val_acc: 0.7825\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 22s 252ms/step - loss: 0.0399 - acc: 0.9878 - val_loss: 0.8982 - val_acc: 0.7840\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 21s 249ms/step - loss: 0.0393 - acc: 0.9890 - val_loss: 0.9110 - val_acc: 0.7812\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 21s 250ms/step - loss: 0.0391 - acc: 0.9891 - val_loss: 0.9080 - val_acc: 0.7815\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.0382 - acc: 0.9887 - val_loss: 0.9137 - val_acc: 0.7808\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 22s 250ms/step - loss: 0.0393 - acc: 0.9888 - val_loss: 0.9143 - val_acc: 0.7801\n",
      "Epoch 90/100\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9880\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "86/86 [==============================] - 21s 250ms/step - loss: 0.0413 - acc: 0.9880 - val_loss: 0.9038 - val_acc: 0.7826\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 22s 258ms/step - loss: 0.0420 - acc: 0.9887 - val_loss: 0.9022 - val_acc: 0.7826\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 22s 250ms/step - loss: 0.0412 - acc: 0.9888 - val_loss: 0.9061 - val_acc: 0.7815\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.0435 - acc: 0.9878 - val_loss: 0.9070 - val_acc: 0.7819\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 21s 250ms/step - loss: 0.0415 - acc: 0.9885 - val_loss: 0.8986 - val_acc: 0.7831\n",
      "Epoch 95/100\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9881\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.0424 - acc: 0.9880 - val_loss: 0.9031 - val_acc: 0.7825\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 22s 255ms/step - loss: 0.0389 - acc: 0.9894 - val_loss: 0.9072 - val_acc: 0.7814\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 22s 251ms/step - loss: 0.0381 - acc: 0.9900 - val_loss: 0.9083 - val_acc: 0.7817\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 22s 257ms/step - loss: 0.0379 - acc: 0.9892 - val_loss: 0.9061 - val_acc: 0.7828\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 22s 250ms/step - loss: 0.0388 - acc: 0.9885 - val_loss: 0.9076 - val_acc: 0.7817\n",
      "Epoch 100/100\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9879\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "86/86 [==============================] - 22s 258ms/step - loss: 0.0427 - acc: 0.9880 - val_loss: 0.9043 - val_acc: 0.7824\n"
     ]
    }
   ],
   "source": [
    "h = model.fit_generator(train_it, epochs=100, validation_data=test_it, callbacks=[tb,ch, redonplat], \n",
    "                        use_multiprocessing=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
